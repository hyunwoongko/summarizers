task_name: "bart_for_text_summarization"
dir_path: "path/to/dir"
batch_size: 16
lr: 3e-5
num_gpus: -1
weight_decay: 1e-4
training_step: 200000
warmup_step: 50000
accumulate_grad_batches: 1
gradient_clip_val: 1.0
accelerator: "ddp"
precision: 16
max_len: 1024
val_check_interval: 1.0
monitor: "val_loss"
use_early_stopping: True
use_tensor_board: True